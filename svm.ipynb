{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18751/1891861820.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv('/content/train_diabetes_health_indicators.csv', delimiter=',')\n",
    "df.dataframeName = 'diabetes_health.csv'\n",
    "nRow, nCol = df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valeur manquant\n",
    "print(f'Colonnes avec valeurs manquantes : { df.isnull().sum()} .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les instances dupliquer\n",
    "lignes_dupliquees = df.duplicated()\n",
    "print(df[lignes_dupliquees])\n",
    "\n",
    "#supprision donnees duplique\n",
    "nombre_lignes_dupliquees = df.duplicated().sum()\n",
    "print(f\"Nombre de lignes dupliquées : {nombre_lignes_dupliquees}\")\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignes_dupliquees = df.duplicated()\n",
    "print(df[lignes_dupliquees])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Les valeurs que prend la cible sont {df[\"Diabetes_012\"].unique()} ')\n",
    "diabetes_target = df[\"Diabetes_012\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = diabetes_target.value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90, colors=['#66b3ff', '#99ff99', '#ffcc99'])\n",
    "plt.title('Proportion des Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_catégorielles = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "#print(\"Colonnes catégorielles :\")\n",
    "print(colonnes_catégorielles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "df_grouped = df.groupby([\"Diabetes_012\"]).mean().apply(lambda col: zscore(col))\n",
    "\n",
    "df_grouped.T.plot.bar()\n",
    "plt.show()\n",
    "\n",
    "df_0 = df[df[\"Diabetes_012\"] == 0]\n",
    "df_1 = df[df[\"Diabetes_012\"] == 1]\n",
    "df_2 = df[df[\"Diabetes_012\"] == 2]\n",
    "\n",
    "X_0 = df_0.drop(\"Diabetes_012\", axis=1)\n",
    "X_1 = df_1.drop(\"Diabetes_012\", axis=1)\n",
    "X_2 = df_2.drop(\"Diabetes_012\", axis=1)\n",
    "\n",
    "X_0_normalized = X_0.apply(lambda col: zscore(col))\n",
    "X_1_normalized = X_1.apply(lambda col: zscore(col))\n",
    "X_2_normalized = X_2.apply(lambda col: zscore(col))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns[1:]:  # Excluez la colonne 'Target'\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.boxplot([X_0[col], X_1[col]])\n",
    "    plt.title(f'Histogramme de {col} pour les classes 0 et 1')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Fréquence')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=\".1f\", linewidths=0.5)\n",
    "plt.title('Matrice de Corrélation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour verifier si on peut supprimer les variable qui ont correlation plus que 0,8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Supposons que vous ayez déjà défini df\n",
    "\n",
    "# Calculer la matrice de corrélation\n",
    "correlation_matrix = df.corr().abs()\n",
    "\n",
    "# Sélectionner la partie supérieure de la matrice de corrélation\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool_))\n",
    "\n",
    "# Trouver les colonnes corrélées avec un seuil\n",
    "threshold = 0.8\n",
    "correlated_columns = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "\n",
    "# Supprimer les colonnes corrélées\n",
    "df_no_corr = df.drop(columns=correlated_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "# Apply standardization to the entire DataFrame\n",
    "df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Diabetes_012\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_standardized, diabetes_target, stratify=diabetes_target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez des poids d'échantillonnage en fonction des classes\n",
    "class_weights = {0: 1, 1: 2, 2: 1}  # Ajustez les poids selon vos besoins\n",
    "\n",
    "# Créez un tableau de poids pour chaque exemple d'entraînement\n",
    "sample_weights = [class_weights[label] for label in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilisation de cross validation\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "# Utilisez la validation croisée stratifiée avec 5 plis\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Créez un modèle SVM\n",
    "svm_model = SVC(class_weight=class_weights, random_state=42)\n",
    "\n",
    "# Entraînez le modèle sur les données d'entraînement\n",
    "svm_model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Prédisez les classes sur les données de test\n",
    "y_pred = svm_model.predict(X_test)\n",
    "# Mesurez les performances du modèle\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(svm_model, open(\"SVM.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
